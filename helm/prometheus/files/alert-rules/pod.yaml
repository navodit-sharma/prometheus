groups:
- name: k8s-pod.rules
  rules:

  - alert: KubernetesPodPending
    expr: group(sum_over_time(kube_pod_status_phase{phase="Pending"}[15m:1m]) == 15) by (namespace,phase,pod,uid)
    for: 0m
    labels:
      severity: critical
    annotations:
      summary: Kubernetes pod is in Pending state
      description: Pod has been in pending state for last 15 minutes. The Pod has been accepted by the Kubernetes cluster, but one or more of the containers has not been set up and made ready to run. This includes time a Pod spends waiting to be scheduled as well as the time spent downloading container images over the network.
      dashboard: Check {{ .ExternalURL | reReplaceAll "(.*)/prometheus" "${1}" }}/d/kubernetes-pods/kubernetes-pods?var-datasource=Prometheus&var-cluster={{ $labels.cluster }}&var-namespace={{ $labels.namespace }}&var-pod={{ $labels.pod }}

  - alert: KubernetesPodFailed
    expr: group(sum_over_time(kube_pod_status_phase{phase="Failed"}[15m:1m]) == 15) by (namespace,phase,pod,uid)
    for: 0m
    labels:
      severity: critical
    annotations:
      summary: Kubernetes pod is in Failed state
      description: Pod has been in failed state for last 15 minutes. All containers in the Pod have terminated, and at least one container has terminated in failure. That is, the container either exited with non-zero status or was terminated by the system.
      dashboard: Check {{ .ExternalURL | reReplaceAll "(.*)/prometheus" "${1}" }}/d/kubernetes-pods/kubernetes-pods?var-datasource=Prometheus&var-cluster={{ $labels.cluster }}&var-namespace={{ $labels.namespace }}&var-pod={{ $labels.pod }}

  - alert: KubernetesPodStateUnknown
    expr: group(sum_over_time(kube_pod_status_phase{phase="Unknown"}[15m:1m]) == 15) by (namespace,phase,pod,uid)
    for: 0m
    labels:
      severity: critical
    annotations:
      summary: Kubernetes pod is in Unknown state
      description: Pod has been in unkwown state for last 15 minutes. For some reason the state of the Pod could not be obtained. This phase typically occurs due to an error in communicating with the node where the Pod should be running.
      dashboard: Check {{ .ExternalURL | reReplaceAll "(.*)/prometheus" "${1}" }}/d/kubernetes-pods/kubernetes-pods?var-datasource=Prometheus&var-cluster={{ $labels.cluster }}&var-namespace={{ $labels.namespace }}&var-pod={{ $labels.pod }}

  - alert: KubernetesPodCrashLoop
    expr: group(increase(kube_pod_container_status_restarts_total[10m]) > 3) by (container,namespace,pod,uid)
    for: 0m
    labels:
      severity: critical
    annotations:
      summary: Kubernetes pod is in CrashLoop state
      description: Pod is crash looping. Pod has crashed more than 3 times in last 10m.
      dashboard: Check {{ .ExternalURL | reReplaceAll "(.*)/prometheus" "${1}" }}/d/kubernetes-pods/kubernetes-pods?var-datasource=Prometheus&var-cluster={{ $labels.cluster }}&var-namespace={{ $labels.namespace }}&var-pod={{ $labels.pod }}
